use Core;
use Core.Text;
use Core.Unicode;
use Core.Diagnostics;
use Core.IO;

// Core.Text & Unicode çµ±åˆã‚µãƒ³ãƒ—ãƒ«ã€‚
// docs/spec/3-3-core-text-unicode.md Â§9ã€Œä½¿ç”¨ä¾‹ã€ã§ç´¹ä»‹ã—ã¦ã„ã‚‹
// tokenize / Grapheme / TextBuilder ã®æµã‚Œã‚’ 1 ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¾ã¨ã‚ã‚‹ã€‚

type Token =
  | Identifier(String)
  | Number(Str)
  | Emoji(Str)
  | DocComment(String)

fn normalize_identifier(bytes: Bytes) -> Result<String, UnicodeError> {
  // Bytes -> Str -> String ã®ä¸‰å±¤å¤‰æ›ã€‚NFC ã§æ­£è¦åŒ–ã—ã¦ã‹ã‚‰è¿”å´ã™ã‚‹ã€‚
  let utf8 = Bytes.decode_utf8(bytes)?;
  Unicode.prepare_identifier(utf8)
}

fn emoji_token(grapheme: Str) -> Result<Token, UnicodeError> {
  // çµµæ–‡å­—ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ãã®ã¾ã¾ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã™ã‚‹ï¼ˆã‚«ãƒ†ã‚´ãƒªæ¤œæŸ»ã¯å‘¼ã³å‡ºã—å…ƒã§æ‹…ä¿ã™ã‚‹ï¼‰ã€‚
  Ok(Emoji(grapheme))
}

fn doc_comment(body: Str) -> Result<Token, UnicodeError> =
  // ã‚³ãƒ¡ãƒ³ãƒˆæœ¬æ–‡ã‚’ NFC ã¸æ­£è¦åŒ–ã—ã€DocComment ã¨ã—ã¦ä¿æŒã™ã‚‹ã€‚
  Unicode.normalize(body, NormalizationForm::NFC).map(|normalized| DocComment(normalized))

fn tokenize_identifier() -> Result<Token, UnicodeError> {
  let raw = Bytes.from_slice("prep_work_ğ‘’ğŸ‘©â€ğŸ’»");
  normalize_identifier(raw).map(|name| Identifier(name))
}

fn tokenize_number() -> Token {
  Number("42.0")
}

fn tokenize_comment() -> Result<Token, UnicodeError> {
  doc_comment("/** è¨­å®š : ï¼¡ï¼©è£œåŠ© */")
}

fn unicode_pipeline() -> Result<List<Token>, UnicodeError> {
  var tokens: List<Token> = List.empty();
  tokens := List.push_back(tokens, tokenize_identifier()?);
  tokens := List.push_back(tokens, tokenize_number());
  tokens := List.push_back(tokens, emoji_token("ğŸ‘©â€ğŸ’»")?);
  tokens := List.push_back(tokens, tokenize_comment()?);
  Ok(tokens)
}

fn emit_stats(tokens: List<Token>) -> Result<(), UnicodeError> {
  let summary = List.map(tokens, |token|
    match token with
      Identifier(name) -> name.as_str()
      Number(value) -> value
      Emoji(grapheme) -> grapheme
      DocComment(text) -> text.as_str()
  );
  let joined = Iter.from(summary).join_with(" ");
  // Grapheme ç›£æŸ»ãƒ­ã‚°ã‚’è¨˜éŒ²ã—ã€reports/spec-audit/ch1/core_text_examples-*.md ã‹ã‚‰å‚ç…§ã™ã‚‹ã€‚
  Diagnostics.log_grapheme_stats(joined)?;
  Ok(())
}

fn sample_decode(path: Str) -> Result<String, UnicodeError> {
  // TextDecodeOptions ã‚’ä½¿ã£ãŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° decodeã€‚
  let reader = IO.Reader::open(path)?;
  let options = TextDecodeOptions {
    bom: BomHandling::Auto,
    invalid: InvalidSequenceStrategy::Replace,
    buffer_size: 4096
  };
  IO.Text.decode_stream(reader, options)
}

fn main() -> Result<List<Token>, UnicodeError> {
  let tokens = unicode_pipeline()?;
  emit_stats(tokens)?;
  Ok(tokens)
}
