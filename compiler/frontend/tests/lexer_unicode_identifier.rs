use reml_frontend::{
    error::FrontendErrorKind,
    lexer::{lex_source_with_options, IdentifierProfile, LexOutput, LexerOptions},
    token::{Token, TokenKind},
};
use reml_runtime::text::LocaleId;

#[derive(Debug)]
struct SuccessCase<'a> {
    name: &'a str,
    identifier: &'a str,
    expected_lexeme: &'a str,
    expected_kind: TokenKind,
    locale: Option<&'a str>,
}

#[derive(Debug)]
struct FailureCase<'a> {
    name: &'a str,
    identifier: &'a str,
    expected_unknown: &'a str,
    expected_message_fragments: &'a [&'a str],
    locale: Option<&'a str>,
}

fn lex_unicode(source: &str, locale: Option<&str>) -> LexOutput {
    let locale = locale.map(|tag| LocaleId::parse(tag).expect("ãƒ­ã‚±ãƒ¼ãƒ«æ–‡å­—åˆ—ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“"));
    let options = LexerOptions {
        identifier_profile: IdentifierProfile::Unicode,
        identifier_locale: locale,
    };
    lex_source_with_options(source, options)
}

fn find_token<'a>(output: &'a LexOutput, kind: TokenKind, lexeme: &str) -> Option<&'a Token> {
    output
        .tokens
        .iter()
        .find(|token| token.kind == kind && token.lexeme.as_deref() == Some(lexeme))
}

const SUCCESS_CASES: &[SuccessCase<'_>] = &[
    SuccessCase {
        name: "normalized_latin",
        identifier: "cafÃ©",
        expected_lexeme: "cafÃ©",
        expected_kind: TokenKind::Identifier,
        locale: None,
    },
    SuccessCase {
        name: "cjk_fullwidth",
        identifier: "è§£æå™¨å…¥åŠ›",
        expected_lexeme: "è§£æå™¨å…¥åŠ›",
        expected_kind: TokenKind::Identifier,
        locale: None,
    },
    SuccessCase {
        name: "emoji_joiner_cluster",
        identifier: "fooğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦bar",
        expected_lexeme: "fooğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦bar",
        expected_kind: TokenKind::Identifier,
        locale: None,
    },
    SuccessCase {
        name: "zwj_arabic",
        identifier: "Ù…Ø«Ø§Ù„\u{200D}Ø§Ø®ØªØ¨Ø§Ø±",
        expected_lexeme: "Ù…Ø«Ø§Ù„\u{200D}Ø§Ø®ØªØ¨Ø§Ø±",
        expected_kind: TokenKind::Identifier,
        locale: None,
    },
    SuccessCase {
        name: "uppercase_greek",
        identifier: "Î”Î¿ÎºÎ¹Î¼Î®",
        expected_lexeme: "Î”Î¿ÎºÎ¹Î¼Î®",
        expected_kind: TokenKind::UpperIdentifier,
        locale: None,
    },
    SuccessCase {
        name: "locale_tr_supported",
        identifier: "k\u{0131}demli",
        expected_lexeme: "k\u{0131}demli",
        expected_kind: TokenKind::Identifier,
        locale: Some("tr-TR"),
    },
];

const FAILURE_CASES: &[FailureCase<'_>] = &[
    FailureCase {
        name: "non_nfc_combining",
        identifier: "cafe\u{0301}",
        expected_unknown: "cafe\u{0301}",
        expected_message_fragments: &["NFC"],
        locale: None,
    },
    FailureCase {
        name: "bidi_rlo",
        identifier: "foo\u{202E}bar",
        expected_unknown: "foo\u{202E}bar",
        expected_message_fragments: &["U+202E"],
        locale: None,
    },
    FailureCase {
        name: "bidi_lri",
        identifier: "foo\u{2066}bar",
        expected_unknown: "foo\u{2066}bar",
        expected_message_fragments: &["U+2066"],
        locale: None,
    },
    FailureCase {
        name: "bidi_rli",
        identifier: "foo\u{2067}bar",
        expected_unknown: "foo\u{2067}bar",
        expected_message_fragments: &["U+2067"],
        locale: None,
    },
    FailureCase {
        name: "bidi_lre",
        identifier: "foo\u{202A}bar",
        expected_unknown: "foo\u{202A}bar",
        expected_message_fragments: &["U+202A"],
        locale: None,
    },
    FailureCase {
        name: "unsupported_locale",
        identifier: "foo",
        expected_unknown: "foo",
        expected_message_fragments: &["lex.identifier_locale", "az-Latn"],
        locale: Some("az-Latn"),
    },
];

#[test]
fn unicode_identifier_success_matrix() {
    for case in SUCCESS_CASES {
        let source = format!("let {} = 1", case.identifier);
        let output = lex_unicode(&source, case.locale);
        assert!(
            output.errors.is_empty(),
            "ã‚±ãƒ¼ã‚¹ `{}` ã§è¨ºæ–­ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {:?}",
            case.name,
            output
                .errors
                .iter()
                .map(|err| err.message())
                .collect::<Vec<_>>()
        );
        let token = find_token(&output, case.expected_kind, case.expected_lexeme).unwrap_or_else(
            || {
                panic!(
                    "ã‚±ãƒ¼ã‚¹ `{}` ã®è­˜åˆ¥å­ `{}` ãŒ TokenKind::{:?} ã¨ã—ã¦å‡ºç¾ã—ã¾ã›ã‚“ã§ã—ãŸã€‚tokens={:?}",
                    case.name, case.expected_lexeme, case.expected_kind, output.tokens
                )
            },
        );
        assert_eq!(
            token.lexeme.as_deref(),
            Some(case.expected_lexeme),
            "ã‚±ãƒ¼ã‚¹ `{}` ã® lexeme ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™",
            case.name
        );
    }
}

#[test]
fn unicode_identifier_error_matrix() {
    for case in FAILURE_CASES {
        let source = format!("let {} = 1", case.identifier);
        let output = lex_unicode(&source, case.locale);
        assert!(
            !output.errors.is_empty(),
            "ã‚±ãƒ¼ã‚¹ `{}` ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã›ãšã€`prepare_identifier` ã®æ¤œè¨¼ãŒã§ãã¾ã›ã‚“",
            case.name
        );
        assert_eq!(
            output.errors.len(),
            1,
            "ã‚±ãƒ¼ã‚¹ `{}` ã¯å˜ä¸€ã‚¨ãƒ©ãƒ¼ã‚’æƒ³å®šã—ã¦ã„ã¾ã™: {:?}",
            case.name,
            output
                .errors
                .iter()
                .map(|err| err.message())
                .collect::<Vec<_>>()
        );
        let error = &output.errors[0];
        let (message, span) = match &error.kind {
            FrontendErrorKind::UnexpectedStructure {
                message,
                span: Some(span),
                ..
            } => (message.clone(), *span),
            other => panic!(
                "ã‚±ãƒ¼ã‚¹ `{}` ãŒ UnexpectedStructure ä»¥å¤–ã®ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã—ã¾ã—ãŸ: {other:?}",
                case.name
            ),
        };
        for fragment in case.expected_message_fragments {
            assert!(
                message.contains(fragment),
                "ã‚±ãƒ¼ã‚¹ `{}` ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã« `{}` ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“: {}",
                case.name,
                fragment,
                message
            );
        }
        let unknown = find_token(&output, TokenKind::Unknown, case.expected_unknown)
            .unwrap_or_else(|| {
                panic!(
                    "ã‚±ãƒ¼ã‚¹ `{}` ã§ Unknown ãƒˆãƒ¼ã‚¯ãƒ³ `{}` ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚tokens={:?}",
                    case.name, case.expected_unknown, output.tokens
                )
            });
        assert_eq!(
            unknown.span, span,
            "ã‚±ãƒ¼ã‚¹ `{}` ã® Unknown ãƒˆãƒ¼ã‚¯ãƒ³ã¨è¨ºæ–­ã®ã‚¹ãƒ‘ãƒ³ãŒä¸€è‡´ã—ã¾ã›ã‚“ï¼ˆtoken={:?}, diag={:?}ï¼‰",
            case.name, unknown.span, span
        );
    }
}
